{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your setup\n",
    "\n",
    "Run the following simple notebook to test your setup. Each of the cells perform different tasks. Feel free to experiment with the different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9990044236183167}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Sentiment analysis\n",
    "text = \"I like Saturdays\"\n",
    "\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = sentiment_analysis(text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ace24ac1c474b229202acbf643483f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e831730c997c4666a1a870a2611f34ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659a1f47e5a549858e28f89db4fd6c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88116fb6bff641cf9d08fbadec80188c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae793cf81d3c45038d9d4404f263088d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985987ebe244412890555a80d5c40786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' Learn and apply strategies for building enterprise AI applications using generative AI software frameworks (e.g., langchain, llamaindex) Fine-tune pre-trained models'}]\n"
     ]
    }
   ],
   "source": [
    "# Text summary\n",
    "\n",
    "text = \"\"\" \n",
    "Marley was dead, to begin with. There is no doubt whatever about that. The register of his burial was signed by the clergyman, the clerk, the undertaker, \n",
    "and the chief mourner. Scrooge signed it. And Scrooge's name was good upon 'Change for anything he chose to put his hand to. Old Marley was as dead as a door-nail.\n",
    "\"\"\"\n",
    "text = \"\"\"\n",
    "Foundational Concepts: Understand the core principles of transformers architecture, their evolution, and their application in building enterprise AI systems.\n",
    "Generative AI Frameworks: Learn and apply strategies for building enterprise AI applications using generative AI software frameworks (e.g., langchain, llamaindex). Fine-tune pre-trained models with available foundational models for specific enterprise tasks, including zero-shot learning on computer vision and retrieval-augmented generation.\n",
    "Performance Optimization: Explore methods to enhance enterprise AI applications using reward-based reinforcement learning for performance optimization.\n",
    "Deployment Strategies: Navigate challenges and strategies for deploying enterprise AI systems in production environments. Optimize models for efficient training and inference, with an understanding of model and data parallelism.\n",
    "Practical Application: Apply theoretical knowledge through practical labs, building and deploying enterprise AI applications in real-world scenarios.\n",
    "\"\"\"\n",
    "\n",
    "summarization = pipeline('summarization')\n",
    "result = summarization(text, min_length=5, max_length=40)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 3f49326 (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64fa3d83b2a482bb850f978a831bc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4cd53c9c434e0ebb28418cd17aea03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e811c2cde1040df934062220eccf05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus', 'score': 0.9973016977310181}, {'label': 'white wolf, Arctic wolf, Canis lupus tundrarum', 'score': 0.0006416403921321034}, {'label': 'Arctic fox, white fox, Alopex lagopus', 'score': 0.0005438797525130212}, {'label': 'brown bear, bruin, Ursus arctos', 'score': 0.00020804785890504718}, {'label': 'American black bear, black bear, Ursus americanus, Euarctos americanus', 'score': 0.00011899494711542502}]\n"
     ]
    }
   ],
   "source": [
    "# Image classification \n",
    "\n",
    "image = 'https://images.ctfassets.net/i04syw39vv9p/4fCAgc3QtfScIGpQiC9xcY/f54afebdbb96b710f66be360c3d85889/Top-5-Favorite-Mom-and-Cub-Facts-02.jpeg'\n",
    "\n",
    "image_classifier = pipeline('image-classification')\n",
    "\n",
    "result = image_classifier(image)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
