{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Large Language Model - Model\n",
    "\n",
    "In this workshop, you will learn how to fine tune the prompts and the LLMs to enhance and improves its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, GenerationConfig, TrainingArguments\n",
    "\n",
    "from peft import PeftModel, LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load and explore the following datasets\n",
    "\n",
    "dataset_name = \"knkarthick/dialogsum\"\n",
    "model_name = \"google/flan-t5-small\"\n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "ds = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': (12460, 4), 'validation': (500, 4), 'test': (1500, 4)}\n",
      "{'id': Value('string'), 'dialogue': Value('string'), 'summary': Value('string'), 'topic': Value('string')}\n",
      "{'id': 'train_10', 'dialogue': \"#Person1#: Could you do me a favor?\\n#Person2#: Sure. What is it?\\n#Person1#: Could you run over to the store? We need a few things.\\n#Person2#: All right. What do you want me to get?\\n#Person1#: Well, could you pick up some sugar?\\n#Person2#: Okay. How much?\\n#Person1#: A small bag. I guess we also need a few oranges.\\n#Person2#: How many?\\n#Person1#: Oh, let's see. . . About six.\\n#Person2#: Anything else?\\n#Person1#: Yes. We're out of milk.\\n#Person2#: Okay. How much do you want me to get? A gallon?\\n#Person1#: No. I think a half gallon will be enough.\\n#Person2#: Is that all?\\n#Person1#: I think so. Have you got all that?\\n#Person2#: Yes. That's small bag of sugar, four oranges, and a half gallon of milk.\\n#Person1#: Do you have enough money?\\n#Person2#: I think so.\\n#Person1#: Thanks very much. I appreciate it.\", 'summary': '#Person1# asks #Person2# to do a favor. #Person2# agrees and helps buy a small bag of sugar, six oranges, and a half-gallon of milk.', 'topic': 'do a favor'}\n",
      "k = id, v = train_10\n",
      "k = dialogue, v = #Person1#: Could you do me a favor?\n",
      "#Person2#: Sure. What is it?\n",
      "#Person1#: Could you run over to the store? We need a few things.\n",
      "#Person2#: All right. What do you want me to get?\n",
      "#Person1#: Well, could you pick up some sugar?\n",
      "#Person2#: Okay. How much?\n",
      "#Person1#: A small bag. I guess we also need a few oranges.\n",
      "#Person2#: How many?\n",
      "#Person1#: Oh, let's see. . . About six.\n",
      "#Person2#: Anything else?\n",
      "#Person1#: Yes. We're out of milk.\n",
      "#Person2#: Okay. How much do you want me to get? A gallon?\n",
      "#Person1#: No. I think a half gallon will be enough.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: I think so. Have you got all that?\n",
      "#Person2#: Yes. That's small bag of sugar, four oranges, and a half gallon of milk.\n",
      "#Person1#: Do you have enough money?\n",
      "#Person2#: I think so.\n",
      "#Person1#: Thanks very much. I appreciate it.\n",
      "k = summary, v = #Person1# asks #Person2# to do a favor. #Person2# agrees and helps buy a small bag of sugar, six oranges, and a half-gallon of milk.\n",
      "k = topic, v = do a favor\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print a record\n",
    "print(ds.shape)\n",
    "\n",
    "idx = 10\n",
    "print(ds['train'].features)\n",
    "print(ds['train'][idx])\n",
    "\n",
    "for k, v in ds['train'][idx].items():\n",
    "   print(f'k = {k}, v = {v}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the LLM model\n",
    "\n",
    "In this workshop we will be turning the <code>google/flan-t5-base</code> model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to dump a model's tunable parameters\n",
    "\n",
    "def print_trainable_model_params(model):\n",
    "   trainable_model_params = 0\n",
    "   all_model_params = 0\n",
    "   for _, param in model.named_parameters():\n",
    "      all_model_params += param.numel()\n",
    "      if param.requires_grad:\n",
    "         trainable_model_params += param.numel()\n",
    "   return f\"Trainable parameters: {trainable_model_params}\\nTotal parameters: {all_model_params}\\nPercentable of trainable parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load model\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 247577856\n",
      "Total parameters: 247577856\n",
      "Percentable of trainable parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print number of trainable parameters\n",
    "print(print_trainable_model_params(original_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 768)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 768)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 12)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-11): 11 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(original_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the dialogue dataset\n",
    "\n",
    "We will train the model to summarize dialogue by creating a dialogue-summary pair for the LLM to process. The dialogue is the training data and the summary is the label. This is supervized learning.\n",
    "\n",
    "The prompt will be as follows\n",
    "\n",
    "```\n",
    "Summarize the following dialogue.\\n\n",
    "\\n\n",
    "Fred: ...\\n\n",
    "Barney: ...\\n\n",
    "\\n\n",
    "Summary:\\n\n",
    "Summary of the conversation between Fred and Barney\n",
    "```\n",
    "\n",
    "The prompt and the summary will be tokenized for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utitlity function to prepare the data for training \n",
    "# Tokenize function\n",
    "def tokenize_fn(data):\n",
    "   start_prompt = 'Summarize the following dialogue.\\n\\n'\n",
    "   end_prompt = '\\n\\nSummary:'\n",
    "   prompt = [ start_prompt + d + end_prompt for d in data['dialogue'] ]\n",
    "   summary = data['summary']\n",
    "   data['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "   data['labels'] = tokenizer(summary, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "   return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: prepare the data for training with the tokenize_fn function\n",
    "tokenized_dataset = ds.map(tokenize_fn, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'train_10', 'dialogue': \"#Person1#: Could you do me a favor?\\n#Person2#: Sure. What is it?\\n#Person1#: Could you run over to the store? We need a few things.\\n#Person2#: All right. What do you want me to get?\\n#Person1#: Well, could you pick up some sugar?\\n#Person2#: Okay. How much?\\n#Person1#: A small bag. I guess we also need a few oranges.\\n#Person2#: How many?\\n#Person1#: Oh, let's see. . . About six.\\n#Person2#: Anything else?\\n#Person1#: Yes. We're out of milk.\\n#Person2#: Okay. How much do you want me to get? A gallon?\\n#Person1#: No. I think a half gallon will be enough.\\n#Person2#: Is that all?\\n#Person1#: I think so. Have you got all that?\\n#Person2#: Yes. That's small bag of sugar, four oranges, and a half gallon of milk.\\n#Person1#: Do you have enough money?\\n#Person2#: I think so.\\n#Person1#: Thanks very much. I appreciate it.\", 'summary': '#Person1# asks #Person2# to do a favor. #Person2# agrees and helps buy a small bag of sugar, six oranges, and a half-gallon of milk.', 'topic': 'do a favor', 'input_ids': [12198, 1635, 1737, 8, 826, 7478, 5, 1713, 345, 13515, 536, 4663, 10, 9348, 25, 103, 140, 3, 9, 4971, 58, 1713, 345, 13515, 357, 4663, 10, 10625, 5, 363, 19, 34, 58, 1713, 345, 13515, 536, 4663, 10, 9348, 25, 661, 147, 12, 8, 1078, 58, 101, 174, 3, 9, 360, 378, 5, 1713, 345, 13515, 357, 4663, 10, 432, 269, 5, 363, 103, 25, 241, 140, 12, 129, 58, 1713, 345, 13515, 536, 4663, 10, 1548, 6, 228, 25, 1432, 95, 128, 2656, 58, 1713, 345, 13515, 357, 4663, 10, 16036, 5, 571, 231, 58, 1713, 345, 13515, 536, 4663, 10, 71, 422, 2182, 5, 27, 3382, 62, 92, 174, 3, 9, 360, 5470, 7, 5, 1713, 345, 13515, 357, 4663, 10, 571, 186, 58, 1713, 345, 13515, 536, 4663, 10, 3359, 6, 752, 31, 7, 217, 5, 3, 5, 3, 5, 4504, 1296, 5, 1713, 345, 13515, 357, 4663, 10, 21345, 1307, 58, 1713, 345, 13515, 536, 4663, 10, 2163, 5, 101, 31, 60, 91, 13, 3702, 5, 1713, 345, 13515, 357, 4663, 10, 16036, 5, 571, 231, 103, 25, 241, 140, 12, 129, 58, 71, 12486, 106, 58, 1713, 345, 13515, 536, 4663, 10, 465, 5, 27, 317, 3, 9, 985, 12486, 106, 56, 36, 631, 5, 1713, 345, 13515, 357, 4663, 10, 27, 7, 24, 66, 58, 1713, 345, 13515, 536, 4663, 10, 27, 317, 78, 5, 2114, 25, 530, 66, 24, 58, 1713, 345, 13515, 357, 4663, 10, 2163, 5, 466, 31, 7, 422, 2182, 13, 2656, 6, 662, 5470, 7, 6, 11, 3, 9, 985, 12486, 106, 13, 3702, 5, 1713, 345, 13515, 536, 4663, 10, 531, 25, 43, 631, 540, 58, 1713, 345, 13515, 357, 4663, 10, 27, 317, 78, 5, 1713, 345, 13515, 536, 4663, 10, 1333, 182, 231, 5, 27, 3653, 34, 5, 20698, 10, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [1713, 345, 13515, 536, 4663, 987, 7, 1713, 345, 13515, 357, 4663, 12, 103, 3, 9, 4971, 5, 1713, 345, 13515, 357, 4663, 2065, 7, 11, 1691, 805, 3, 9, 422, 2182, 13, 2656, 6, 1296, 5470, 7, 6, 11, 3, 9, 985, 18, 6191, 40, 106, 13, 3702, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "k = id, v = train_10\n",
      "k = dialogue, v = #Person1#: Could you do me a favor?\n",
      "#Person2#: Sure. What is it?\n",
      "#Person1#: Could you run over to the store? We need a few things.\n",
      "#Person2#: All right. What do you want me to get?\n",
      "#Person1#: Well, could you pick up some sugar?\n",
      "#Person2#: Okay. How much?\n",
      "#Person1#: A small bag. I guess we also need a few oranges.\n",
      "#Person2#: How many?\n",
      "#Person1#: Oh, let's see. . . About six.\n",
      "#Person2#: Anything else?\n",
      "#Person1#: Yes. We're out of milk.\n",
      "#Person2#: Okay. How much do you want me to get? A gallon?\n",
      "#Person1#: No. I think a half gallon will be enough.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: I think so. Have you got all that?\n",
      "#Person2#: Yes. That's small bag of sugar, four oranges, and a half gallon of milk.\n",
      "#Person1#: Do you have enough money?\n",
      "#Person2#: I think so.\n",
      "#Person1#: Thanks very much. I appreciate it.\n",
      "k = summary, v = #Person1# asks #Person2# to do a favor. #Person2# agrees and helps buy a small bag of sugar, six oranges, and a half-gallon of milk.\n",
      "k = topic, v = do a favor\n",
      "k = input_ids, v = [12198, 1635, 1737, 8, 826, 7478, 5, 1713, 345, 13515, 536, 4663, 10, 9348, 25, 103, 140, 3, 9, 4971, 58, 1713, 345, 13515, 357, 4663, 10, 10625, 5, 363, 19, 34, 58, 1713, 345, 13515, 536, 4663, 10, 9348, 25, 661, 147, 12, 8, 1078, 58, 101, 174, 3, 9, 360, 378, 5, 1713, 345, 13515, 357, 4663, 10, 432, 269, 5, 363, 103, 25, 241, 140, 12, 129, 58, 1713, 345, 13515, 536, 4663, 10, 1548, 6, 228, 25, 1432, 95, 128, 2656, 58, 1713, 345, 13515, 357, 4663, 10, 16036, 5, 571, 231, 58, 1713, 345, 13515, 536, 4663, 10, 71, 422, 2182, 5, 27, 3382, 62, 92, 174, 3, 9, 360, 5470, 7, 5, 1713, 345, 13515, 357, 4663, 10, 571, 186, 58, 1713, 345, 13515, 536, 4663, 10, 3359, 6, 752, 31, 7, 217, 5, 3, 5, 3, 5, 4504, 1296, 5, 1713, 345, 13515, 357, 4663, 10, 21345, 1307, 58, 1713, 345, 13515, 536, 4663, 10, 2163, 5, 101, 31, 60, 91, 13, 3702, 5, 1713, 345, 13515, 357, 4663, 10, 16036, 5, 571, 231, 103, 25, 241, 140, 12, 129, 58, 71, 12486, 106, 58, 1713, 345, 13515, 536, 4663, 10, 465, 5, 27, 317, 3, 9, 985, 12486, 106, 56, 36, 631, 5, 1713, 345, 13515, 357, 4663, 10, 27, 7, 24, 66, 58, 1713, 345, 13515, 536, 4663, 10, 27, 317, 78, 5, 2114, 25, 530, 66, 24, 58, 1713, 345, 13515, 357, 4663, 10, 2163, 5, 466, 31, 7, 422, 2182, 13, 2656, 6, 662, 5470, 7, 6, 11, 3, 9, 985, 12486, 106, 13, 3702, 5, 1713, 345, 13515, 536, 4663, 10, 531, 25, 43, 631, 540, 58, 1713, 345, 13515, 357, 4663, 10, 27, 317, 78, 5, 1713, 345, 13515, 536, 4663, 10, 1333, 182, 231, 5, 27, 3653, 34, 5, 20698, 10, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "k = labels, v = [1713, 345, 13515, 536, 4663, 987, 7, 1713, 345, 13515, 357, 4663, 12, 103, 3, 9, 4971, 5, 1713, 345, 13515, 357, 4663, 2065, 7, 11, 1691, 805, 3, 9, 422, 2182, 13, 2656, 6, 1296, 5470, 7, 6, 11, 3, 9, 985, 18, 6191, 40, 106, 13, 3702, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'][idx])\n",
    "for k, v in tokenized_dataset['train'][idx].items():\n",
    "   print(f'k = {k}, v = {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following dialogue. #Person1#: Happy Birthday, this is for you, Brian. #Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time. #Person1#: Brian, may I have a pleasure to have a dance with you? #Person2#: Ok. #Person1#: This is really wonderful party. #Person2#: Yes, you are always popular with everyone. and you look very pretty today. #Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel. #Person2#: You look great, you are absolutely glowing. #Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday Summary:\n",
      "#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Verify prepared data\n",
    "print(tokenizer.decode(tokenized_dataset['test'][idx]['input_ids'], skip_special_tokens=True))\n",
    "print(tokenizer.decode(tokenized_dataset['test'][idx]['labels'], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value('string'), 'dialogue': Value('string'), 'summary': Value('string'), 'topic': Value('string'), 'input_ids': List(Value('int32')), 'labels': List(Value('int64'))}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove id, dialogue, summary and topic columns from dataset. We only want input_ids and labels\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(\n",
    "   [ 'id', 'dialogue', 'summary', 'topic' ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': List(Value('int32')), 'labels': List(Value('int64'))}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Verify dataset again\n",
    "print(tokenized_dataset['train'].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune model with pre-processed dataset\n",
    "\n",
    "We will use [<code>Trainer</code>](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#api-reference%20][%20transformers.Trainer) to train the original model. The training result will be written out. The trainer will be configure with [<code>TrainingArgument</code>](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "# CUDA information\n",
    "\n",
    "print('CUDA available: ', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "   print('B16 supported: ', torch.cuda.is_bf16_supported())\n",
    "   torch.cuda.set_device(0)\n",
    "   print('Current device: ', torch.cuda.current_device())\n",
    "   print('CUDA device name: ', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the LLM Model with Low-Rank Adaptation (LoRA) / Parameter Efficient Fine Tuning (PEFT)\n",
    "\n",
    "We will add a LoRA adapter to the LLM (flan-t5-base) and train the adapter. The original LLM will be frozen. The adapter can be combined with the original LLM during inferencing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "   # smaller means be better at what it is currently doing, \n",
    "   # larger means ability learn new concepts / 'things'\n",
    "   r = 16,\n",
    "   lora_alpha=16,\n",
    "   target_modules=['q','v'], \n",
    "   lora_dropout=0.05,\n",
    "   bias=\"none\",\n",
    "   task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add LoRA to the LLM model to be trained\n",
    "lora_model = get_peft_model(original_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1769472\n",
      "Total parameters: 249347328\n",
      "Percentable of trainable parameters: 0.71%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print number of parameters, compare LoRA to the original model\n",
    "print(print_trainable_model_params(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train model with LoRA\n",
    "output_dir = f'peft-model-checkpoint-{str(int(time.time()))}'\n",
    "lora_training_args = TrainingArguments(\n",
    "   output_dir=output_dir,\n",
    "   auto_find_batch_size=True, \n",
    "   learning_rate=1e-3,\n",
    "   max_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create trainer and train model\n",
    "lora_trainer = Trainer(\n",
    "   model=lora_model,\n",
    "   args = lora_training_args,\n",
    "   train_dataset = tokenized_dataset['train'],\n",
    "   eval_dataset = tokenized_dataset['validation']\n",
    ")\n",
    "\n",
    "#lora_trainer.train()\n",
    "\n",
    "#lora_trainer.model.save_pretrained('chuk/flan-t5-instruct')\n",
    "#tokenizer.save_pretrained('chuk/flan-65-instruct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a trained LoRA model\n",
    "\n",
    "The training will take a few hours and over many iterations.\n",
    "\n",
    "For the purpose of this workshop we use a save model [intotheverse/peft-dialogue-summary-checkpoint](https://huggingface.co/intotheverse/peft-dialogue-summary-checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 0\n",
      "Total parameters: 251116800\n",
      "Percentable of trainable parameters: 0.00%\n"
     ]
    }
   ],
   "source": [
    "#TODO: Load the original model and add the pre-trained LoRA adaptation to the model\n",
    "peft_dialogue_summary_checkpoint = 'intotheverse/peft-dialogue-summary-checkpoint'\n",
    "\n",
    "lora_base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "      lora_base_model, \n",
    "      peft_dialogue_summary_checkpoint,\n",
    "      torch_dtype=torch.bfloat16, \n",
    "      is_trainable=False)\n",
    "\n",
    "print(print_trainable_model_params(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate LoRA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate LoRA model against the original \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "i = 1\n",
      "i = 2\n",
      "i = 3\n",
      "i = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original_model_summary</th>\n",
       "      <th>lora_model_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
       "      <td>The memo is to be distributed to all employees...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In order to prevent employees from wasting tim...</td>\n",
       "      <td>The memo is to be distributed to all employees...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
       "      <td>The memo is to be distributed to all employees...</td>\n",
       "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2# arrives late because of traffic jam....</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
       "      <td>The traffic jam at the Carrefour intersection ...</td>\n",
       "      <td>#Person2# got stuck in traffic and #Person1# s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
       "1  In order to prevent employees from wasting tim...   \n",
       "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
       "3  #Person2# arrives late because of traffic jam....   \n",
       "4  #Person2# decides to follow #Person1#'s sugges...   \n",
       "\n",
       "                              original_model_summary  \\\n",
       "0  The memo is to be distributed to all employees...   \n",
       "1  The memo is to be distributed to all employees...   \n",
       "2  The memo is to be distributed to all employees...   \n",
       "3  The traffic jam at the Carrefour intersection ...   \n",
       "4  The traffic jam at the Carrefour intersection ...   \n",
       "\n",
       "                                  lora_model_summary  \n",
       "0  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "1  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "2  #Person1# asks Ms. Dawson to take a dictation ...  \n",
       "3  #Person2# got stuck in traffic and #Person1# s...  \n",
       "4  #Person2# got stuck in traffic and #Person1# s...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for evaluation\n",
    "dialogues = []\n",
    "summaries = []\n",
    "orig_model_summaries = []\n",
    "lora_model_summaries = []\n",
    "dataset = ds\n",
    "config = GenerationConfig(max_new_tokens=200)\n",
    "\n",
    "for i in range(5):\n",
    "   print(f'i = {i}')\n",
    "   d = dataset['test'][i]['dialogue']\n",
    "   s = dataset['test'][i]['summary']\n",
    "   prompt = f\"Summarize the following conversation.\\n\\n{d}\\n\\nSummary:\"\n",
    "   tokenized_prompt = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "   orig_resp = original_model.generate(input_ids=tokenized_prompt, generation_config=config)\n",
    "   orig_resp_text = tokenizer.decode(orig_resp[0], skip_special_tokens=True)\n",
    "   lora_resp = lora_model.generate(input_ids=tokenized_prompt, generation_config=config)\n",
    "   lora_resp_text = tokenizer.decode(lora_resp[0], skip_special_tokens=True)\n",
    "\n",
    "   summaries.append(s)\n",
    "   orig_model_summaries.append(orig_resp_text)\n",
    "   lora_model_summaries.append(lora_resp_text)\n",
    "\n",
    "zipped_summaries = list(zip(summaries, orig_model_summaries, lora_model_summaries))\n",
    "df = pd.DataFrame(zipped_summaries, columns=['label', 'original_model_summary', 'lora_model_summary'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models with ROUGE/Bleu metrics\n",
    "\n",
    "Recall-Oriented Understudy for Gisting Evaluate ([ROUGE](https://pub.aimind.so/unveiling-the-power-of-rouge-metrics-in-nlp-b6d3f96d3363)) is a set of metrics used to evaluate the quality of machine-generated text, such as summaries and translations. ROUGE metrics compare the generated text to a human-written reference and measure the overlap between the two. \n",
    "\n",
    "The metrics range between 0 and 1, with higher scores indicating higher similarity between the baseline and generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create ROUGE metrics\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the original model's result\n",
    "orig_model_results = rouge.compute(\n",
    "   references=summaries,\n",
    "   predictions=orig_model_summaries,\n",
    "   use_aggregator=True,\n",
    "   use_stemmer=True\n",
    ")\n",
    "\n",
    "loral_model_results = rouge.compute(\n",
    "   references=summaries,\n",
    "   predictions=lora_model_summaries,\n",
    "   use_aggregator=True,\n",
    "   use_stemmer=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: {'rouge1': np.float64(0.17391941391941393), 'rouge2': np.float64(0.03820816864295125), 'rougeL': np.float64(0.13364468864468865), 'rougeLsum': np.float64(0.13364468864468865)}\n",
      "------------\n",
      "LoRA: {'rouge1': np.float64(0.34193513803269904), 'rouge2': np.float64(0.1024924201890494), 'rougeL': np.float64(0.2728511771470072), 'rougeLsum': np.float64(0.2728511771470072)}\n"
     ]
    }
   ],
   "source": [
    "print('original:', orig_model_results)\n",
    "\n",
    "print('------------')\n",
    "\n",
    "print('LoRA:', loral_model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate with Bleu metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
